import os
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from supabase import create_client, Client

# ğŸš€ ConfiguraciÃ³n del tema y ancho de pÃ¡gina
st.set_page_config(page_title="KingCrab - Bolsa de Trabajo", page_icon="ğŸ“Š", layout="wide")

# ğŸ“‚ Sidebar con informaciÃ³n y logo
st.sidebar.title("KingCrab ğŸ“Š")
st.sidebar.markdown("### AnÃ¡lisis de Mercado Laboral en Tiempo Real")
st.sidebar.info(
    "Esta aplicaciÃ³n extrae y analiza datos de diferentes portales de empleo "
    "para ofrecerte tendencias laborales actualizadas."
)
st.sidebar.markdown("---")
st.sidebar.write("ğŸ‘¨â€ğŸ’» Desarrollado por [Tu Nombre]")

# ğŸ“¡ CONEXIÃ“N A SUPABASE
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# ğŸ“¤ OBTENER DATOS DESDE SUPABASE
response = supabase.table("Trabajos").select("titulo, url, fecha_publicacion").execute()
df = pd.DataFrame(response.data)

# ğŸ“Š **Procesar datos**
df["fecha_publicacion"] = pd.to_datetime(df["fecha_publicacion"], errors='coerce')
df = df.dropna(subset=["fecha_publicacion"])
df["fecha_publicacion"] = df["fecha_publicacion"].dt.date

# ğŸ“Š **Extraer palabras mÃ¡s comunes**
word_list = " ".join(df["titulo"].dropna().tolist()).lower().split()
word_freq = pd.Series(word_list).value_counts().reset_index()
word_freq.columns = ["Palabra", "Frecuencia"]
word_freq = word_freq[~word_freq["Palabra"].isin(["de", "y", "en", "para", "con", "el", "la"])]
top_words = word_freq.head(5)

# ğŸ”¢ **DiseÃ±o de Streamlit con 3 columnas**
col1, col2, col3 = st.columns([1, 1, 1])

# ğŸ“Š **GrÃ¡fico de Barras en la primera columna**
with col1:
    st.markdown("### ğŸ“Š Palabras mÃ¡s repetidas")
    fig, ax = plt.subplots(figsize=(4, 3))
    sns.barplot(x=top_words["Frecuencia"], y=top_words["Palabra"], palette="magma", ax=ax)
    ax.set_title("Palabras MÃ¡s Comunes", fontsize=10)
    st.pyplot(fig)

# â˜ï¸ **Nube de Palabras en la segunda columna**
with col2:
    st.markdown("### â˜ï¸ Nube de palabras")
    wordcloud = WordCloud(width=400, height=200, background_color="white").generate(" ".join(word_list))
    fig, ax = plt.subplots(figsize=(4, 3))
    ax.imshow(wordcloud, interpolation="bilinear")
    ax.axis("off")
    st.pyplot(fig)

# ğŸ“… **LÃ­nea de Tiempo en la tercera columna**
with col3:
    st.markdown("### â³ Publicaciones a lo largo del tiempo")
    fecha_freq = df["fecha_publicacion"].value_counts().sort_index()
    
    if not fecha_freq.empty:
        fig, ax = plt.subplots(figsize=(4, 3))
        sns.lineplot(x=fecha_freq.index, y=fecha_freq.values, marker='o', ax=ax)
        ax.set_title("Publicaciones por Fecha", fontsize=10)
        plt.xticks(rotation=45)
        st.pyplot(fig)
    else:
        st.write("ğŸ“‰ No hay suficientes datos para mostrar la lÃ­nea de tiempo.")

# ğŸ” **Filtro de BÃºsqueda**
st.markdown("## ğŸ” Buscar Trabajo")
titulo_filtro = st.text_input("ğŸ” Escribe un tÃ­tulo de trabajo:")

# ğŸ“ **Filtrar en la base de datos en tiempo real**
if titulo_filtro:
    response = supabase.table("Trabajos").select("titulo, url").ilike("titulo", f"%{titulo_filtro}%").execute()
    df_filtrado = pd.DataFrame(response.data)
else:
    df_filtrado = df.copy()

# ğŸ”— **Convertir URL en HipervÃ­nculos**
df_filtrado["url"] = df_filtrado["url"].apply(lambda x: f"[ğŸ”— Ver oferta]({x})" if x else "No disponible")

# ğŸ“‹ **Mostrar Resultados en la tabla**
st.markdown("### ğŸ“‹ Resultados de bÃºsqueda:")
st.write(df_filtrado.to_markdown(index=False), unsafe_allow_html=True)
